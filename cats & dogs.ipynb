{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## changing directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "\n",
    "from os import makedirs \n",
    "from os import listdir \n",
    "from shutil import copyfile \n",
    "from random import seed \n",
    "from random import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing alignment of directories, so that it is used in ImageDataGenerator\n",
    "dataset_home = 'dataset_dogs_vs_cats/' \n",
    "subdirs = ['train/', 'test/']\n",
    "for subdir in subdirs: \n",
    "    # create label subdirectories\n",
    "    labeldirs = ['dogs/', 'cats/'] \n",
    "    for labldir in labeldirs:\n",
    "        newdir = dataset_home + subdir + labldir\n",
    "        makedirs(newdir, exist_ok=True) \n",
    "# seed random number generator\n",
    "seed(1) \n",
    "# define ratio of pictures to use for validation \n",
    "val_ratio = 0.25 \n",
    "# copy training dataset images into subdirectories \n",
    "src_directory = 'train/train/'\n",
    "for file in listdir(src_directory):\n",
    "    src = src_directory + '/' + file\n",
    "    dst_dir = 'train/'\n",
    "    if random() < val_ratio: \n",
    "        dst_dir = 'test/'\n",
    "    if file.startswith('cat'):\n",
    "        dst = dataset_home + dst_dir + 'cats/' + file\n",
    "        copyfile(src, dst) \n",
    "    elif file.startswith('dog'):\n",
    "        dst = dataset_home + dst_dir + 'dogs/' + file\n",
    "        copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18697 images belonging to 2 classes.\n",
      "Found 6303 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_datagen.flow_from_directory('C:/Users/Arun/dataset_dogs_vs_cats/train',target_size=(200,200),class_mode='binary',batch_size=  64)\n",
    "validation = validation_datagen.flow_from_directory('C:/Users/Arun/dataset_dogs_vs_cats/test',target_size=(200,200),class_mode='binary',batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vgg_block(layer_in,f1,f2,f3):\n",
    "    layer_in = Conv2D(f1,(3,3),padding ='same',activation ='relu',kernel_initializer='he_uniform')(layer_in)\n",
    "    layer_in = MaxPooling2D((2,2))(layer_in)\n",
    "    layer_in = Dropout(0.2)(layer_in)\n",
    "    layer_in = Conv2D(f2,(3,3),padding ='same',activation ='relu',kernel_initializer='he_uniform')(layer_in)        \n",
    "    layer_in = MaxPooling2D((2,2))(layer_in)\n",
    "    layer_in = Dropout(0.2)(layer_in)\n",
    "    layer_in = Conv2D(f3,(3,3),padding ='same',activation ='relu',kernel_initializer='he_uniform')(layer_in)\n",
    "    layer_in = MaxPooling2D((2,2))(layer_in)\n",
    "    layer_in = Dropout(0.2)(layer_in)\n",
    "    \n",
    "    return layer_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape= (200,200,3))\n",
    "layer1= vgg_block(input,32,64,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = Flatten()(layer1)\n",
    "dense1 = Dense(128,activation='relu',kernel_initializer='he_uniform')(flat)\n",
    "drop = Dropout(0.5)(dense1)\n",
    "output = Dense(1,activation='sigmoid')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 80000)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               10240128  \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,333,505\n",
      "Trainable params: 10,333,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr = 0.001,momentum = 0.9)\n",
    "model.compile(optimizer= opt,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "293/293 [==============================] - 579s 2s/step - loss: 0.6980 - accuracy: 0.5175 - val_loss: 0.6856 - val_accuracy: 0.5683\n",
      "Epoch 2/20\n",
      "293/293 [==============================] - 595s 2s/step - loss: 0.6888 - accuracy: 0.5338 - val_loss: 0.6927 - val_accuracy: 0.5707\n",
      "Epoch 3/20\n",
      "293/293 [==============================] - 601s 2s/step - loss: 0.6841 - accuracy: 0.5508 - val_loss: 0.6828 - val_accuracy: 0.5896\n",
      "Epoch 4/20\n",
      "293/293 [==============================] - 609s 2s/step - loss: 0.6776 - accuracy: 0.5631 - val_loss: 0.6763 - val_accuracy: 0.5921\n",
      "Epoch 5/20\n",
      "293/293 [==============================] - 579s 2s/step - loss: 0.6721 - accuracy: 0.5778 - val_loss: 0.6488 - val_accuracy: 0.5443\n",
      "Epoch 6/20\n",
      "293/293 [==============================] - 581s 2s/step - loss: 0.6634 - accuracy: 0.5907 - val_loss: 0.6841 - val_accuracy: 0.6069\n",
      "Epoch 7/20\n",
      "293/293 [==============================] - 591s 2s/step - loss: 0.6533 - accuracy: 0.6036 - val_loss: 0.6676 - val_accuracy: 0.5781\n",
      "Epoch 8/20\n",
      "293/293 [==============================] - 586s 2s/step - loss: 0.6444 - accuracy: 0.6171 - val_loss: 0.6108 - val_accuracy: 0.5827\n",
      "Epoch 9/20\n",
      "293/293 [==============================] - 581s 2s/step - loss: 0.6341 - accuracy: 0.6268 - val_loss: 0.6918 - val_accuracy: 0.5943\n",
      "Epoch 10/20\n",
      "293/293 [==============================] - 579s 2s/step - loss: 0.6247 - accuracy: 0.6437 - val_loss: 0.6901 - val_accuracy: 0.6338\n",
      "Epoch 11/20\n",
      "293/293 [==============================] - 586s 2s/step - loss: 0.6193 - accuracy: 0.6498 - val_loss: 0.6229 - val_accuracy: 0.6486\n",
      "Epoch 12/20\n",
      "293/293 [==============================] - 593s 2s/step - loss: 0.6131 - accuracy: 0.6544 - val_loss: 0.6314 - val_accuracy: 0.6183\n",
      "Epoch 13/20\n",
      "293/293 [==============================] - 596s 2s/step - loss: 0.6061 - accuracy: 0.6615 - val_loss: 0.5577 - val_accuracy: 0.6237\n",
      "Epoch 14/20\n",
      "293/293 [==============================] - 604s 2s/step - loss: 0.6067 - accuracy: 0.6594 - val_loss: 0.5820 - val_accuracy: 0.6684\n",
      "Epoch 15/20\n",
      "293/293 [==============================] - 590s 2s/step - loss: 0.6014 - accuracy: 0.6699 - val_loss: 0.5602 - val_accuracy: 0.6651\n",
      "Epoch 16/20\n",
      "293/293 [==============================] - 583s 2s/step - loss: 0.5943 - accuracy: 0.6778 - val_loss: 0.5519 - val_accuracy: 0.6498\n",
      "Epoch 17/20\n",
      "293/293 [==============================] - 587s 2s/step - loss: 0.5915 - accuracy: 0.6804 - val_loss: 0.6287 - val_accuracy: 0.6700\n",
      "Epoch 18/20\n",
      "293/293 [==============================] - 595s 2s/step - loss: 0.5862 - accuracy: 0.6860 - val_loss: 0.6654 - val_accuracy: 0.6781\n",
      "Epoch 19/20\n",
      "293/293 [==============================] - 610s 2s/step - loss: 0.5855 - accuracy: 0.6893 - val_loss: 0.4755 - val_accuracy: 0.6752\n",
      "Epoch 20/20\n",
      "293/293 [==============================] - 600s 2s/step - loss: 0.5821 - accuracy: 0.6914 - val_loss: 0.6112 - val_accuracy: 0.6913\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train,steps_per_epoch=len(train),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.evaluate_generator(validation, steps=len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6939552426338196"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
